# gRINN Web Service Environment Configuration
# Copy this file to .env and customize for your deployment

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
# For local development, use SQLite (no setup required)
DATABASE_URL=sqlite:////tmp/grinn_dev.db

# For production, use PostgreSQL
# DATABASE_URL=postgresql://grinn_user:your_password@localhost:5432/grinn_web

# =============================================================================
# LOCAL STORAGE CONFIGURATION
# =============================================================================
# Path to store job files (use NFS mount for multi-worker setups)
STORAGE_PATH=/data/grinn-jobs

# Job file retention period in hours (default: 72 = 3 days)
# After this period, job files are deleted and status changes to EXPIRED
JOB_FILE_RETENTION_HOURS=72

# How long to keep expired job records in the database (default: 30 days)
# After this period, expired jobs are permanently deleted from the database
EXPIRED_JOB_RETENTION_DAYS=30

# How often the cleanup task runs in seconds (default: 21600 = 6 hours)
# Set lower for testing (e.g., 30 for 30 seconds)
CLEANUP_INTERVAL_SECONDS=21600

# =============================================================================
# WORKER REGISTRATION
# =============================================================================
# Token for worker authentication (generate with: python -c "import secrets; print(secrets.token_urlsafe(32))")
# WORKER_REGISTRATION_TOKEN=your-secure-token-here

# Worker facility name
WORKER_FACILITY=main-facility

# =============================================================================
# REDIS CONFIGURATION
# =============================================================================
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================
# Backend API server
BACKEND_HOST=0.0.0.0
BACKEND_PORT=5000

# Backend API public URL (proxied through nginx)
BACKEND_PUBLIC_URL=https://grinn.bio-cloud.site/api

# Dashboard public URL template (proxied through nginx)
DASHBOARD_PUBLIC_URL_TEMPLATE=https://grinn.bio-cloud.site/dashboard/{port}

# Frontend dashboard
FRONTEND_HOST=0.0.0.0
FRONTEND_PORT=8051
FRONTEND_DEBUG=false

# Public hostname/IP for client-facing URLs (e.g., download links, dashboard iframes)
# If not set, defaults to the system hostname (socket.gethostname())
# For remote access, set this to your server's public IP or domain name
# PUBLIC_HOST=your-server.example.com

# Full URL override for backend API (for reverse proxy setups)
# Use this when the backend is proxied through nginx/apache on a different path or port
# Example: https://example.com/api (nginx proxies /api/* to localhost:5000/api/*)
# If not set, defaults to http://{PUBLIC_HOST}:{BACKEND_PORT}
# BACKEND_PUBLIC_URL=https://your-server.example.com/api

# =============================================================================
# GRINN DOCKER CONFIGURATION
# =============================================================================
GRINN_DOCKER_IMAGE=grinn:gromacs-2024.1
DOCKER_TIMEOUT=3600

# =============================================================================
# GRINN DASHBOARD DOCKER CONFIGURATION
# =============================================================================
# Docker image for interactive dashboard visualization
DASHBOARD_DOCKER_IMAGE=grinn-dashboard:latest

# Port range for dashboard instances (one port per active dashboard)
DASHBOARD_PORT_START=8100
DASHBOARD_PORT_END=8200

# Auto-stop inactive dashboards after timeout (seconds, 0 to disable)
DASHBOARD_TIMEOUT=3600

# Maximum concurrent dashboard instances
# When this limit is reached, "Launch Dashboard" buttons will be disabled
# and users will be directed to download results and use standalone gRINN
DASHBOARD_MAX_INSTANCES=10

# Idle timeout for dashboard cleanup (minutes)
# Dashboards without heartbeats for this duration will be stopped
DASHBOARD_IDLE_TIMEOUT_MINUTES=5

# How often to check for idle dashboards (seconds)
DASHBOARD_CLEANUP_INTERVAL_SECONDS=60

DASHBOARD_PORT_RANGE_START=8100
DASHBOARD_PORT_RANGE_END=8200

# Public hostname/IP for dashboard URLs (used in dashboard iframe links)
# If not set, defaults to PUBLIC_HOST (or system hostname if PUBLIC_HOST is also not set)
# DASHBOARD_PUBLIC_HOST=your-server.example.com

# Full URL template for dashboard instances (for reverse proxy setups)
# Use {job_id} as placeholder for the job ID
# Example: https://example.com/api/dashboard/{job_id} (backend proxies to dashboard container)
# If not set, defaults to http://{DASHBOARD_PUBLIC_HOST}:{port} (direct port access)
# DASHBOARD_PUBLIC_URL_TEMPLATE=https://your-server.example.com/api/dashboard/{job_id}

# =============================================================================
# AI CHATBOT CONFIGURATION
# =============================================================================
# Gemini API key for dashboard chatbot
GEMINI_API_KEY=
# Anthropic API key for dashboard chatbot
ANTHROPIC_API_KEY=
# Available LLM models shown in the chatbot dropdown.
# Accepts JSON array, comma-separated, or newline-separated values.
# Examples:
# PANDASAI_MODELS=["gemini/gemini-pro-latest","gemini/gemini-1.5-pro-latest"]
# PANDASAI_MODELS=gemini/gemini-pro-latest,gemini/gemini-1.5-pro-latest
PANDASAI_MODELS=

# Default selection for the dropdown (optional).
# If set, it will be auto-inserted into PANDASAI_MODELS if missing.
PANDASAI_DEFAULT_MODEL=

# Backward-compatible single-model setting (still supported).
# PANDASAI_MODEL=gemini/gemini-pro-latest

# Token budget per dashboard session (chatbot). When exhausted, queries are blocked.
# Set to 0 or leave empty for unlimited.
PANDASAI_TOKEN_LIMIT=1000

# Enable/disable Docker sandbox for chatbot code execution.
# When true (default for standalone), LLM-generated code runs in isolated Docker container.
# When false, code executes locally (used for dashboard containers where Docker-in-Docker unavailable).
# WARNING: Disabling sandbox executes LLM-generated code without isolation - only use in trusted environments.
PANDASAI_USE_DOCKER_SANDBOX=true

# =============================================================================
# FILE UPLOAD LIMITS
# =============================================================================
# Hard limit for trajectory-class files (XTC/TRR in trajectory mode, PDB in ensemble mode)
# LARGE_FILE_THRESHOLD_MB takes precedence if both are set
MAX_TRAJECTORY_FILE_SIZE_MB=100
LARGE_FILE_THRESHOLD_MB=100

# Hard limit for structure/topology files (PDB in trajectory mode, GRO, TOP, TPR, ITP, etc.)
MAX_OTHER_FILE_SIZE_MB=10

# Optional global cap: fail preflight if exceeded
# Applies to trajectory frames (XTC/TRR) and ensemble PDB models
MAX_FRAMES=

JOB_RETENTION_DAYS=3

# =============================================================================
# CAPACITY LIMITS
# =============================================================================
# Maximum concurrent jobs running across all workers (global limit)
MAX_CONCURRENT_JOBS=10

# Maximum jobs that can be queued (waiting to be processed) at once
# New submissions will be rejected with 503 when this limit is reached
MAX_QUEUED_JOBS=50

# Maximum concurrent jobs per worker (worker-specific limit)
# Workers can declare different capacities during registration
WORKER_MAX_CONCURRENT_JOBS=2

# Worker heartbeat settings for health monitoring
WORKER_HEARTBEAT_INTERVAL_SECONDS=30
WORKER_HEARTBEAT_TIMEOUT_SECONDS=90

# =============================================================================
# SECURITY
# =============================================================================
# Generate secure random strings for production
SECRET_KEY=dev-secret-key-change-in-production
JWT_SECRET_KEY=dev-jwt-secret-change-in-production

# Upload directory (ensure write permissions)
UPLOAD_FOLDER=/tmp/grinn-uploads

# =============================================================================
# LOGGING AND DEVELOPMENT
# =============================================================================
LOG_LEVEL=INFO
LOG_FORMAT=detailed
FLASK_ENV=development
DASH_ENV=development
DEBUG=true

# =============================================================================
# WORKER CONFIGURATION
# =============================================================================
CELERY_WORKER_CONCURRENCY=2
CELERY_WORKER_MAX_TASKS_PER_CHILD=1000

# Example data paths for "Load Example Data" button (mode-specific)
# Trajectory mode: Should contain structure (.pdb/.gro), trajectory (.xtc/.trr), and topology (.top/.tpr) files
EXAMPLE_DATA_PATH_TRAJECTORY=/path/to/trajectory_example_data

# Ensemble mode: Should contain a single multi-model PDB file with MODEL/ENDMDL records
EXAMPLE_DATA_PATH_ENSEMBLE=/path/to/ensemble_example_data